"""
Script para extraer y guardar el StandardScaler usado en el entrenamiento
Ejecutar este script en el entorno donde se entren√≥ el modelo

Uso:
    python extraer_scaler.py
"""

from pathlib import Path

import joblib
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler


def extraer_scaler_del_preprocesamiento():
    """
    Extrae el scaler del proceso de preprocesamiento
    Si tienes el pipeline completo, extr√°elo de ah√≠
    Si no, crea uno nuevo con el dataset de entrenamiento
    """

    print("=" * 70)
    print("EXTRACCI√ìN DEL STANDARDSCALER")
    print("=" * 70)

    # Opci√≥n 1: Intentar cargar scaler si ya existe en alg√∫n lado
    posibles_rutas = [
        "output/models/scaler.pkl",
        "output/scaler.pkl",
        "scaler.pkl",
    ]

    for ruta in posibles_rutas:
        if Path(ruta).exists():
            print(f"\n‚úì Scaler encontrado en: {ruta}")
            scaler = joblib.load(ruta)

            # Guardar en las ubicaciones correctas
            Path("output/models/experiment_a").mkdir(parents=True, exist_ok=True)
            Path("app").mkdir(exist_ok=True)

            joblib.dump(scaler, "output/models/experiment_a/scaler.pkl")
            joblib.dump(scaler, "app/scaler.pkl")

            print("‚úì Scaler copiado a:")
            print("  - output/models/experiment_a/scaler.pkl")
            print("  - app/scaler.pkl")
            return scaler

    # Opci√≥n 2: Crear scaler nuevo desde el dataset
    print("\n‚ö†Ô∏è  Scaler no encontrado, creando uno nuevo...")
    print("    Cargando dataset para entrenar scaler...")

    try:
        # Cargar dataset procesado
        dataset_path = "dataset_final_formateado.xlsx"
        if not Path(dataset_path).exists():
            print(f"\n‚ùå No se encontr√≥ {dataset_path}")
            print("\nOpciones:")
            print("1. Coloca el dataset en la ra√≠z del proyecto")
            print("2. O ejecuta el pipeline completo (main.py) que generar√° el scaler")
            return None

        df = pd.read_excel(dataset_path)
        print(f"‚úì Dataset cargado: {len(df)} registros, {len(df.columns)} columnas")

        # Seleccionar solo columnas num√©ricas (excluyendo target)
        target_col = "Valoracion_Terreno"

        # Columnas num√©ricas para escalar
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if target_col in numeric_cols:
            numeric_cols.remove(target_col)

        print(f"‚úì Columnas num√©ricas a escalar: {len(numeric_cols)}")

        # Crear y entrenar scaler
        scaler = StandardScaler()
        scaler.fit(df[numeric_cols])

        print("‚úì Scaler entrenado exitosamente")

        # Guardar
        Path("output/models/experiment_a").mkdir(parents=True, exist_ok=True)
        Path("app").mkdir(exist_ok=True)

        joblib.dump(scaler, "output/models/experiment_a/scaler.pkl")
        joblib.dump(scaler, "app/scaler.pkl")

        print("\n‚úì Scaler guardado en:")
        print("  - output/models/experiment_a/scaler.pkl")
        print("  - app/scaler.pkl")

        # Verificar
        print("\nüìä Informaci√≥n del Scaler:")
        print(f"  - Mean shape: {scaler.mean_.shape}")
        print(f"  - Scale shape: {scaler.scale_.shape}")
        print(f"  - Features procesadas: {len(scaler.mean_)}")

        return scaler

    except Exception as e:
        print(f"\n‚ùå Error al crear scaler: {e}")
        print("\nüí° Soluci√≥n: Ejecuta el pipeline completo (main.py) primero")
        return None


def verificar_scaler(scaler):
    """Verifica que el scaler funcione correctamente"""
    if scaler is None:
        return False

    print("\n" + "=" * 70)
    print("VERIFICACI√ìN DEL SCALER")
    print("=" * 70)

    try:
        # Crear datos de prueba
        test_data = np.random.randn(1, len(scaler.mean_))
        scaled = scaler.transform(test_data)

        print(f"‚úì Scaler funciona correctamente")
        print(f"  - Input shape: {test_data.shape}")
        print(f"  - Output shape: {scaled.shape}")
        print(f"  - Mean del input: {test_data.mean():.4f}")
        print(f"  - Mean del output: {scaled.mean():.4f}")
        print(f"  - Std del output: {scaled.std():.4f}")

        return True

    except Exception as e:
        print(f"‚ùå Error al verificar scaler: {e}")
        return False


def main():
    print("\nüîß Script de Extracci√≥n del StandardScaler\n")

    scaler = extraer_scaler_del_preprocesamiento()

    if scaler:
        if verificar_scaler(scaler):
            print("\n" + "=" * 70)
            print("‚úÖ PROCESO COMPLETADO EXITOSAMENTE")
            print("=" * 70)
            print("\nPr√≥ximos pasos:")
            print("1. Ejecuta la app: streamlit run app/app.py")
            print("2. La app ahora usar√° el scaler autom√°ticamente")
            print("3. Las predicciones deber√≠an ser correctas")
        else:
            print("\n" + "=" * 70)
            print("‚ö†Ô∏è  SCALER CREADO PERO CON PROBLEMAS")
            print("=" * 70)
    else:
        print("\n" + "=" * 70)
        print("‚ùå NO SE PUDO CREAR EL SCALER")
        print("=" * 70)
        print("\nüí° Soluci√≥n:")
        print("1. Ejecuta el pipeline completo: python main.py")
        print("2. Esto generar√° todos los archivos necesarios incluyendo el scaler")
        print("3. Luego ejecuta la app: streamlit run app/app.py")


if __name__ == "__main__":
    main()
